{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24877bf7-accf-44ac-b20e-487af1000cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "import transformer\n",
    "from config import Config, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4783c02-5dbd-4702-a80a-c7b4505e1b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embed): Embed()\n",
       "  (pos): PositionalEmbed()\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): RMSNorm()\n",
       "      (attn): SelfAttention()\n",
       "      (ln2): RMSNorm()\n",
       "      (mlp): GatedFFN(\n",
       "        (W1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "        (W2): Linear(in_features=2048, out_features=768, bias=False)\n",
       "        (V): Linear(in_features=768, out_features=2048, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"gpt-step31728.pt\"\n",
    "checkpoint =  load_checkpoint(path)\n",
    "cfg = Config(**checkpoint['model_cfg'])\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "model = transformer.TransformerModel(cfg).to('cuda', dtype=torch.bfloat16)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9ae2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, prompt, n_samples):\n",
    "    prompt_tokens = enc.encode(prompt)\n",
    "    generated = []\n",
    "    for i in range(n_samples):\n",
    "        context = prompt_tokens + generated\n",
    "        if len(context) > model.cfg.ctx_len:\n",
    "            context = context[-model.cfg.ctx_len:]\n",
    "        logits = model(torch.tensor(context).view(1, -1)).squeeze(0)\n",
    "        probs = logits.softmax(-1)\n",
    "        next = torch.multinomial(probs[-1], num_samples = 1).item()\n",
    "        generated.append(next)\n",
    "\n",
    "    return prompt + enc.decode(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd71168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 8.1177e-03, -1.5625e-02, -7.1526e-05,  ..., -1.0864e-02,\n",
       "          1.3123e-02, -5.9814e-03],\n",
       "        [ 9.3384e-03, -7.2632e-03,  7.9346e-03,  ...,  3.2715e-02,\n",
       "         -7.8125e-03, -1.4465e-02],\n",
       "        [ 3.0151e-02, -4.8218e-03,  1.9897e-02,  ..., -3.2227e-02,\n",
       "         -9.8877e-03, -2.4719e-03],\n",
       "        ...,\n",
       "        [-5.7983e-04,  9.9945e-04, -1.9531e-03,  ..., -3.7842e-03,\n",
       "         -1.3351e-03, -1.3351e-03],\n",
       "        [ 3.2196e-03,  3.2501e-03,  2.1973e-03,  ...,  3.7231e-03,\n",
       "         -3.6011e-03, -3.8147e-03],\n",
       "        [-2.6512e-04, -4.6730e-04, -1.3123e-03,  ..., -1.9989e-03,\n",
       "          4.3945e-03, -3.3722e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.embed.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50dd455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int main(x:\\^ ~ / \\\\E\\) is defined as an allos = \\(\\lambda \\Duq Int ) { \\(\\lambda \\Duq Int ) {This is the n_0+\\) in the bytes between the last 1x, the second followed by the remaining 2x s, and the first followed by the unseabables, making the rest of the digit \\((i\\) explicitly defined by linear intamehq */ in the 5\\) to achieve 0.\n",
      "\n",
      "8 Objects\n",
      "\n",
      "The same string properties are actually functions represented by subsequent vectors of integers. The top instead follows one can be represented by the equator array with f( X-A, qA), Int(x, y)x, DRY, and FLY equals multiplicative_ function types. Using first, the sub implicit the “method” of the relation is quoted within the identifier keyword, the structs as output elements in fractional math. Other functions include seqC, Fn(X), T(x, ZPtr) and transfits. Different weights typically consist of strings, or many others. This example though is the middle nine “method” that is the key key. The data is composed of two A, double A, and four Non-quantant Gaussian orthons.\n",
      "\n",
      "This functionality is striking. The “method” can be imprisoned very much rapidly in a precision fashion, and not hampered by doubts. For example: how much D=(1, 2 2 ) gen, ϕ(1, 1) δ(*i): | ⅜ + ₂·· 22 {\\displaystyle sin(=\\lambda \\Duq Double ) {K(Q(\\(x,b)); + \\end {\\{d|dx|AC(-{2,1} + \\; ?||i|ύ$,\\}|+|\\u)}{|FG(Aý)+\\{E(x, y})+\\{Rg,}{\\\\\\{d|}{ =\\x}!:(\\x|||\\)\\>\\u\\in(1 +\\_(X+\\)!}+)\\|”');\n",
      "\n",
      "Then, multiplication is given\n",
      "\n",
      "The target isn is an types\n",
      "\n",
      "$$ \\{\\begin{aggregate}}}\n",
      "\n",
      "We can compute the number of relations between two variable variables altogether and we could expect significant timeframes. A function values instead of the integral (geo and z apply this list for the agglutations), but A function generalizes the identity information of an algorithm.\n",
      "\n",
      "Supplense Naumerin is a Median C++ predicate which defines how the p defined condition gives a 0 cl. Im;\n",
      "\n",
      "defend = Int(w) list[2, 3].\n",
      "\n",
      "After generating string sum through vertices, the predicate yield the number of parameters some(de and Z) will correspond toUTFIn(p) fixed probabilities. This is the second function to construct the statistical results. The values are set by with (items of some object) (if not insIterator , are used[3] and then apply a 1 hit to the digit is 'usually after November, epoch only).\n",
      "\n",
      "The result must be a better representation of the inner method, it is a more variable than requirement, but it is the one function of a function being expressed by Int $ &\n",
      "\n",
      "2 a = cos(y = 1); then, Int def unsigned integers .\n",
      "\n",
      "We want to consider the binary character Total numbers in the table that are prime expressions measured by a ∼ x $cc to nine1. Question which contains a ∼ x form. Suppose we expect an integer(Empty a, char< 100, y)\\):\n",
      "\n",
      "() constructor P .. c Intel { C Wendels = 0; Finest; Mock(); Printb, t : 0;\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, \"int main(\", 800))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
